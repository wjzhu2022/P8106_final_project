---
title: "final_project"
author: "wz2631 rz2614 jn2855"
date: "2023-04-30"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(collapse = TRUE, message = FALSE, warning = FALSE)
library(plyr)
library(caret)
library(FNN) 
library(dplyr)
library(ggplot2)
library(caret)
library(pROC)
library(partykit)
library(randomForest)
library(mlbench)
library(ranger)
library(ISLR)
library(MASS)
library(knitr)
library(earth)
library(mgcv)
library(party)
library(doBy) 
library(tidyverse)
library(parallel)
library(doParallel)
```



### Data preparation
```{r}
# draw 2 random samples of 2000 participants
load("./recovery.Rdata")
set.seed(2631) 
dat1 <- dat[sample(1:10000, 2000),] %>% 
  janitor::clean_names() %>% 
  na.omit()
set.seed(2855) 
dat2 <- dat[sample(1:10000, 2000),] %>% 
  janitor::clean_names() %>% 
  na.omit() 
dat <- rbind.fill(dat1, dat2) %>%
   dplyr::select(-id) %>% 
  unique() %>% mutate( gender = fct_recode(factor(gender),male = '1',female = '0'),
    race = fct_recode(factor(race),white = '1',asian = '2',black = '3',hispanic = '4'),
    smoking = fct_recode(factor(smoking),never = '0',former = '1',current = '2'),
    hypertension = factor(hypertension),
    diabetes = factor(diabetes),
    vaccine = factor(vaccine),
    severity = factor(severity),
    study = factor(study)
  ) 
```

```{r}
#data partition
set.seed(2023)
train_index = createDataPartition(y = dat$recovery_time,
                                p = 0.8,
                                list = FALSE)
train_dat = dat[train_index,]
test_dat = dat[-train_index,]
#training data
train_data = dat[train_index,]
x1 = model.matrix(recovery_time~., data = dat)[train_index,-1]
y1 = dat$recovery_time[train_index]
#testing data
test_data = dat[-train_index,]
x2 = model.matrix(recovery_time~., data = dat)[-train_index,-1]
y2 = dat$recovery_time[-train_index]  
```

```{r warning=FALSE}
#exploratory analysis and data visualization
visualization = train_dat %>% 
  mutate(study = case_when(
    study == "A" ~ 1,
    study == "B" ~ 2,
    study == "C" ~ 3
  )) %>% 
  dplyr::select(ldl,weight,bmi,sbp,age,height)
non_numeric = sapply(visualization, function(x) !is.numeric(x))
visualization[, non_numeric] = lapply(visualization[, non_numeric], as.numeric) 
theme1 = trellis.par.get()
theme1$plot.symbol$col = rgb(.2, .4, .2, .5)
theme1$plot.symbol$pch = 16
theme1$plot.line$col = rgb(.8, .1, .1, 1)
theme1$plot.line$lwd = 2
theme1$strip.background$col = rgb(.0, .2, .6, .2)
trellis.par.set(theme1)

featurePlot(x = visualization[ ,1:6],
            y = visualization[ ,6],
            plot = "scatter",
            span = .5,
            labels = c("Predictors", "Recovery Time"),
            main = "Figure 1. the relationship between predictors and recovery time",
            type = c("p", "smooth"))
```

```{r}
par(mfrow = c(2,2)) 
boxplot(recovery_time~study, data = dat, xlab = "study", ylim = c(0,150))
boxplot(recovery_time~gender, data = dat, xlab = "gender", ylim = c(0,150))
boxplot(recovery_time~hypertension, data = dat, xlab = "hypertension", ylim = c(0,150))
boxplot(recovery_time~diabetes, data = dat, xlab = "diabetes", ylim = c(0,150))
boxplot(recovery_time~vaccine, data = dat, xlab = "vaccine", ylim = c(0,150))
boxplot(recovery_time~severity, data = dat, xlab = "severity", ylim = c(0,150))
boxplot(recovery_time~race, data = dat, xlab = "race", ylim = c(0,150))
boxplot(recovery_time~smoking, data = dat, xlab = "smoking", ylim = c(0,150))
```

```{r lm}
#linear model
set.seed(2023)
ctrl = trainControl(method = "repeatedcv", number = 10, repeats = 5)
linear = train(recovery_time ~ age + gender + race + smoking + height + 
                        weight + bmi + hypertension + diabetes + sbp + ldl + vaccine + severity + study, 
               data = train_dat, 
               method = "lm", 
               trControl = ctrl)
summary(linear$finalModel)
par(mfrow=c(2,2)) 
plot(linear$finalModel)
test_pred1 = predict(linear,newdata = test_dat)
lm.rmse = sqrt(mean((test_pred1 - test_dat$recovery_time)**2))
lm.rmse
```

```{r lasso}
#lasso
set.seed(2023)
ctrl=trainControl(method = "repeatedcv", number =10, repeats = 5)
lasso=train(x1,y1, 
            method = "glmnet",
                   tuneGrid = expand.grid(alpha = 1,
                                          lambda = exp(seq(-5, 5, length = 100))),
                   trControl = ctrl)
coef(lasso$finalModel, lasso$bestTune$lambda)
lasso$bestTunetest_pred2=predict(lasso,newdata=x2)
pred_lasso=predict(lasso, newx = x2, s = lasso$lambda.min)
rmse_lasso= sqrt(mean((pred_lasso-y2)**2))
rmse_lasso
coef=coef(lasso, s = lasso$lambda.min)
n.pred=sum(coef[-1] != 0)  
n.pred
plot(lasso)
```

```{r ridge}
#ridge
set.seed(2023)

ridge = train(x1, y1,
                 method = "glmnet",
                 tuneGrid = expand.grid(alpha = 0,
                                        lambda = exp(seq(-1, 6, length = 100))), 
                 trControl = ctrl)
summary(ridge$finalModel)
plot(ridge, xTrans = log)

ridge$bestTune$lambda
coef(ridge$finalModel, ridge$bestTune$lambda)

ridge.pred <- predict(ridge, newdata = x2) 
ridge.rmse <- sqrt(mean((ridge.pred - y2)^2))
ridge.rmse
```

```{r elastic net}
#elastic net
set.seed(2023)
elastic_net = train(x1, y1,
                  method = "glmnet",
                  tuneGrid = expand.grid(alpha = seq(0, 1, length = 21), 
                                         lambda = exp(seq(10, -10, length = 50))),
                  trControl = ctrl)
elastic_net$bestTune
test_pred_elastic = predict(elastic_net, newdata = x2)
enet.rmse = sqrt(mean((test_pred_elastic - test_dat$recovery_time)**2))
enet.rmse
plot(elastic_net)
```

```{r pls}
#pls
set.seed(2023)
pls=train(x1, y1,
          method = "pls",
          tuneGrid = data.frame(ncomp = 1:20), 
          trControl = ctrl,
          preProcess = c("center", "scale"))

summary(pls$finalModel)
test_pred_pls=predict(pls, newdata = x2)
rmse_pls=sqrt(mean((test_pred_pls - test_dat$recovery_time)**2))
rmse_pls
plot(pls)
```

```{r pcr}
#pcr
set.seed(2023)

pcr.fit <- train(x1, y1,
                 method = "pcr",
                 tuneGrid = data.frame(ncomp = 1:19),
                 trControl = ctrl,
                 preProcess = c("center","scale"))
summary(pcr.fit$finalModel)
ggplot(pcr.fit, highlight = TRUE) + theme_bw()

pcr.pred = predict(pcr.fit, newdata = x2)
pcr.rmse = sqrt(mean((pcr.pred - y2)^2))
pcr.rmse
```

```{r mars}
#mars
library(parallel)
# Calculate the number of cores
num_cores <- detectCores() 
library(doParallel)
# create the cluster for caret to use
# CPU usage may go up to 100%
cl <- makePSOCKcluster(num_cores)
registerDoParallel(cl)
set.seed(2023)
mars_grid = expand.grid(degree = 1:3, 
                        nprune = 2:18) 
mars = train(x1, y1,
             method = "earth",
             tuneGrid = mars_grid,
             trControl = ctrl)
kable(mars$bestTune,"simple")
coef(mars$finalModel)
test_pred_mars = predict(mars, newdata = x2)
rmse_mars = sqrt(mean((test_pred_mars - test_dat$recovery_time)**2))
rmse_mars
summary(mars)
plot(mars)
stopCluster(cl)
registerDoSEQ()
```

```{r gam}
#gam 
num_cores <- detectCores() 
library(doParallel)
# create the cluster for caret to use
# CPU usage may go up to 100%
cl <- makePSOCKcluster(num_cores)
registerDoParallel(cl)
gam = train(x1, y1,
                 method = "gam",
                 trControl = ctrl,
                 control = gam.control(maxit = 200))
summary(gam$finalModel)
gam$df.residual
test_pred_gam = predict(gam, newdata = x2)
rmse_gam = sqrt(mean((test_pred_gam - test_dat$recovery_time)**2))
rmse_gam
plot(gam)
stopCluster(cl)
registerDoSEQ()
```

```{r tree}
#tree
library(parallel)
# Calculate the number of cores
num_cores <- detectCores() 
library(doParallel)
# create the cluster for caret to use
# CPU usage may go up to 100%
cl <- makePSOCKcluster(num_cores)
registerDoParallel(cl)
set.seed(2023)
rpart_fit <- train(recovery_time ~., data = dat[train_index,], 
                     method = "rpart",
                     tuneGrid = data.frame(cp = exp(seq(-6, -2, length = 50))),
                     trControl = ctrl)
rpart_fit$bestTune
ggplot(rpart_fit,highlight = TRUE)

test_pred_tree = predict(rpart_fit, newdata = dat[-train_index, ])
rmse_tree = mean((test_pred_tree - dat$recovery_time[-train_index])**2)
rmse_tree
stopCluster(cl)
registerDoSEQ()
```
The cp value is `r rpart_fit$finalModel$tuneValue[[1]]`.

```{r rf}
#rf
library(parallel)
# Calculate the number of cores
num_cores <- detectCores() 
library(doParallel)
# create the cluster for caret to use
# CPU usage may go up to 100%
cl <- makePSOCKcluster(num_cores)
registerDoParallel(cl)
rf_grid = expand.grid(mtry = 1:16,
                       splitrule = "variance",
                       min.node.size = 1:6)
set.seed(2023)
rf_fit = train(recovery_time ~., 
                data = dat[train_index,],
                method = "ranger",
                tuneGrid = rf_grid,
                trControl = ctrl)
rf_fit$bestTune
ggplot(rf_fit,highlight = TRUE)
test_pred_rf = predict(rf_fit, newdata = dat[-train_index, ])
rmse_rf = mean((test_pred_rf - dat$recovery_time[-train_index])**2)
rmse_rf
stopCluster(cl)
registerDoSEQ()
```

```{r boosting}
#boosting

num_cores <- detectCores() 

cl <- makePSOCKcluster(num_cores)
registerDoParallel(cl)
set.seed(2023)
gbm_grid = expand.grid(n.trees = c(1000,2000, 3000, 4000, 5000),
                       interaction.depth = 1:5,
                       shrinkage = c(0.001,0.003,0.005),
                       n.minobsinnode = c(1, 10))
gbm_fit = train(recovery_time ~ . , 
                train_dat, 
                method = "gbm",
                tuneGrid = gbm_grid,
                trControl = ctrl,
                verbose = FALSE)
gbm_fit$bestTune

summary(gbm_fit$finalModel, las = 2, cBars = 19, cex.names = 0.6)
pred_gbm = predict(gbm_fit, newdata = test_dat)
rmse_gbm = RMSE(pred_gbm,dat$recovery_time[-train_index])
rmse_gbm
stopCluster(cl)
registerDoSEQ()
```


```{r svm}
#svm
cl <- makePSOCKcluster(num_cores)
registerDoParallel(cl)

set.seed(2023)
radial_tune = tune.svm(recovery_time ~ .,
                        data = dat[train_index,],
                        kernel = "radial",
                        cost = exp(seq(-1,4,len = 20)),
                        gamma = exp(seq(-6,-2,len = 20)))
plot(radial_tune, transform.y = log, transform.x = log,
     color.palette = terrain.colors)

best_radial = radial_tune$best.model
summary(best_radial)
pred.radial = predict(best_radial,newdata = dat[-train_index,])
confusionMatrix(data = pred.radial,reference = dat$recovery_time[-train_index])

stopCluster(cl)
registerDoSEQ()
```

### Model comparison and selection
```{r}
model <- c("LM","RIDGE","LASSO","ENET","PCR","PLS","GAM","MARS","TREE","RF","BOOSTING","SVM")
test_rmse <- c(lm.rmse, ridge.rmse, lasso.rmse, enet.rmse, pcr.rmse, rmse_pls, rmse_gam, rmse_mars, rmse_tree, rmse_rf, rmse_gbm, rmse_svm)
test_rmse_df <- cbind(model, test_rmse)
test_rmse_df <- as.data.frame(test_rmse_df)
test_rmse_df
resamp <- resamples(list(LM = linear,
                         RIDGE = ridge,
                         LASSO = lasso,
                         ENET = elastic_net,
                         PCR = pcr.fit,
                         PLS = pls,
                         GAM = gam,
                         MARS = mars,
                         TREE = rpart_fit,
                         RF = rf_fit,
                         BOOSTING = gbm_fit,
                         SVM = radial_tune))
summary(resamp)
bwplot(resamp, metric = "RMSE")
```

```{r model comparison}
#model comparison
set.seed(2023)
res=resamples(list(boosting=gbm_fit,rf=rf_fit))
summary(res)
```

```{r}
bwplot(res, 
       metric = "RMSE",
       main = "Figure 2. Model Comparison")
```

