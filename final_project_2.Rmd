---
title: "final_project"
author: "wz2631 rz2614 jn2855"
date: "2023-04-30"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(collapse = TRUE, message = FALSE, warning = FALSE)
library(plyr)
library(dplyr)
library(caret)
library(FNN) 
library(dplyr)
library(kernlab)
library(factoextra)
library(e1071)
library(ggplot2)
library(caret)
library(pROC)
library(partykit)
library(randomForest)
library(mlbench)
library(ranger)
library(ISLR)
library(MASS)
library(knitr)
library(earth)
library(mgcv)
library(party)
library(doBy) 
library(tidyverse)
library(ggplot2)
library(ggridges)
library(vip)
set.seed(2023)
```

### Data preparation
```{r}
# draw 2 random samples of 2000 participants
load("./recovery.Rdata")
set.seed(2631) 
dat1 <- dat[sample(1:10000, 2000),] %>% 
  janitor::clean_names() %>% 
  na.omit()
set.seed(2855) 
dat2 <- dat[sample(1:10000, 2000),] %>% 
  janitor::clean_names() %>% 
  na.omit() 
dat <- rbind.fill(dat1, dat2) %>%
   dplyr::select(-id) %>% 
  unique() %>% mutate( gender=fct_recode(factor(gender),male='1',female='0'),
    race = fct_recode(factor(race),white='1',asian='2',black='3',hispanic='4'),
    smoking = fct_recode(factor(smoking),never='0',former='1',current='2'),
    hypertension = factor(hypertension),
    diabetes = factor(diabetes),
    vaccine = factor(vaccine),
    severity = factor(severity),
    study = factor(study),
    recovery_t = if_else(recovery_time <= 30, 't1','t2')
  ) 
```

```{r}
#data partition
set.seed(2023)
data <- dat %>%
  mutate(recovery_t = factor(recovery_t))
levels(data$recovery_t) = c("t1", "t2")
training_rows <- createDataPartition(data$recovery_t,
                                     p = 0.8,
                                     list = F)
training_set <- data[training_rows,]
train_x <- model.matrix(recovery_t~., data %>% 
                          dplyr::select(-recovery_time))[training_rows,-1]
train_y <- data$recovery_t[training_rows]
test_set <- data[-training_rows,]
test_x <- model.matrix(recovery_t~., data %>% 
                         dplyr::select(-recovery_time))[-training_rows,-1]
test_y <- data$recovery_t[-training_rows]
```

```{r warning=FALSE}
#exploratory analysis and data visualization
visualization = train_dat %>% 
  mutate(study=case_when(
    study == "A" ~ 1,
    study == "B" ~ 2,
    study == "C" ~ 3
  )) %>% 
  dplyr::select(ldl,weight,bmi,sbp,age,height)
non_numeric= sapply(visualization, function(x) !is.numeric(x))
visualization[, non_numeric] = lapply(visualization[, non_numeric], as.numeric) 
theme1 = trellis.par.get()
theme1$plot.symbol$col = rgb(.2, .4, .2, .5)
theme1$plot.symbol$pch=16
theme1$plot.line$col=rgb(.8, .1, .1, 1)
theme1$plot.line$lwd=2
theme1$strip.background$col=rgb(.0, .2, .6, .2)
trellis.par.set(theme1)

featurePlot(x = visualization[ ,1:6],
            y = visualization[ ,6],
            plot = "scatter",
            span = .5,
            labels = c("Predictors", "Recovery Time"),
            main = "Figure 1. the relationship between predictors and recovery time",
            type = c("p", "smooth"))
```

```{r}
par(mfrow=c(2,2)) 
boxplot(recovery_t~study, data=data, xlab="study", ylim=c(0,150))
boxplot(recovery_t~gender, data=data, xlab="gender", ylim=c(0,150))
boxplot(recovery_t~hypertension, data=data, xlab="hypertension", ylim=c(0,150))
boxplot(recovery_t~diabetes, data=data, xlab="diabetes", ylim=c(0,150))
boxplot(recovery_t~vaccine, data=data, xlab="vaccine", ylim=c(0,150))
boxplot(recovery_t~severity, data=data, xlab="severity", ylim=c(0,150))
boxplot(recovery_t~race, data=data, xlab="race", ylim=c(0,150))
boxplot(recovery_t~smoking, data=data, xlab="smoking", ylim=c(0,150))

```
```{r tree warning=FALSE}
ctrl.c <- trainControl(method = "cv", number = 10)
set.seed(2)
gbm_grid <- expand.grid(
  n.trees = c(50, 100, 200, 500, 1000, 2000),
  interaction.depth = 1:5,
  shrinkage = c(0.005,0.01,0.015),
  n.minobsinnode = c(1,5))
library(doParallel)
Mycluster = makeCluster(detectCores() - 2)
registerDoParallel(Mycluster)
boost_fit <- train(train_x,
                   train_y,
                   method = "gbm",
                   tuneGrid = gbm_grid,
                   trControl = ctrl.c,
                   distribution = "adaboost",
                   verbose = FALSE)
stopCluster(Mycluster)
registerDoSEQ()

ggplot(boost_fit, highlight = TRUE)
boost_fit$bestTune
summary(boost_fit$finalModel,las = 2, cBars = 19, cex.names = 0.6)

pred_gbm = predict(gbm_fit, newdata = test_data)
rmse_gbm = RMSE(pred_gbm,dat$recovery_t[-train_index])
rmse_gbm
```



```{r raw tree}
#tree
set.seed(2023)
ctrl = trainControl(method = "repeatedcv", number = 10, repeats = 5, savePredictions = TRUE)
rpart_fit <- train(recovery_t ~., 
                   data = train_x, 
                     method = "rpart",
                     tuneGrid = data.frame(cp = exp(seq(-6, -2, length = 50))),
                     trControl = ctrl)
rpart_fit$bestTune
ggplot(rpart_fit,highlight = TRUE)

test_pred_tree = predict(rpart_fit, newdata = dat[-train_index, ])
rmse_tree = sqrt(mean((test_pred_tree - dat$recovery_t[-train_index])**2))
rmse_tree
rpart.plot::rpart.plot(rpart_fit$finalModel)

```
The cp value is `r rpart_fit$finalModel$tuneValue[[1]]`.

```{r}
#bagging
library(parallel)
# Calculate the number of cores
num_cores <- detectCores() 
library(doParallel)
# create the cluster for caret to use
# CPU usage may go up to 100%
cl <- makePSOCKcluster(num_cores)
registerDoParallel(cl)
rf_grid=expand.grid(mtry = 1:16,
                       splitrule = "variance",
                       min.node.size = 1:6)
set.seed(2023)
rf_fit=train(recovery_t ~., 
                data = train_dat,
                method = "ranger",
                tuneGrid = rf_grid,
                trControl = ctrl)
rf_fit$bestTune
ggplot(rf_fit,highlight=TRUE)
pred_tree = predict(rf_fit, newdata = test_dat)
rmse_tree = RMSE(pred_tree,dat$recovery_t[-train_index])
stopCluster(cl)
registerDoSEQ()
```

```{r boosting}
#boosting

num_cores <- detectCores() 

cl <- makePSOCKcluster(num_cores)
registerDoParallel(cl)
set.seed(2023)
gbm_grid = expand.grid(n.trees = c(1000,2000, 3000, 4000, 5000),
                       interaction.depth = 1:5,
                       shrinkage = c(0.001,0.003,0.005),
                       n.minobsinnode = c(1, 10))
gbm_fit = train(recovery_t ~ . , 
                train_dat, 
                method = "gbm",
                tuneGrid = gbm_grid,
                trControl = ctrl,
                verbose = FALSE)
gbm_fit$bestTune

summary(gbm_fit$finalModel, las = 2, cBars = 19, cex.names = 0.6)
pred_gbm = predict(gbm_fit, newdata = test_dat)
rmse_gbm = RMSE(pred_gbm,dat$recovery_t[-train_index])
rmse_gbm
stopCluster(cl)
registerDoSEQ()
```

```{r svm}
#svm
cl <- makePSOCKcluster(num_cores)
registerDoParallel(cl)

set.seed(2023)


svmr_grid <- expand.grid(C = exp(seq(-2,2,len=40)),
                         sigma = exp(seq(-1,2,len=30)))

svmr_fit <- train(recovery_t ~.,
                  data = train_dat,
                  method = "svmRadialSigma",
                  tuneGrid = svmr_grid,
                  trControl = ctrl)

stopCluster(cl)
registerDoSEQ()

```

```{r}
svmr_fit$bestTune
svm_test_prediction <- predict(svmr_fit$finalModel, newdata = x2)
myCol=rainbow(25)
myPar <- list(superpose.symbol = list(col = myCol), 
              superpose.line = list(col = myCol))
plot(svmr_fit, highlight = TRUE, par.settings = myPar)
test_pred_svm=predict(svmr_fit, newdata = dat[-train_index,])

test_error_svm=sqrt(mean((test_pred_svm - dat$recovery_t[-train_index])^2))
```

```{r}
#model comparison
env <- foreach:::.foreachGlobals
rm(list=ls(name=env), pos=env)

resamp <- resamples(list(TREE = rpart_fit,
                         RF = rf_fit,
                         BOOSTING = gbm_fit,
                         SVM = svmr_fit))
summary(resamp)
bwplot(resamp, metric = "ROC")

model_rank =
  resamp$values %>%
  dplyr::select(ends_with("Rsquared")) %>%
  pivot_longer('LM~Rsquared':'SVM~Rsquared',names_to = "model", values_to = "Rsquared",names_pattern = "(.*)~Rsquared") %>%
  group_by(model) %>%
  summarize(Rsquared_mean=mean(Rsquared),Rsquared_sd = sd(Rsquared)) %>%
  arrange(Rsquared_mean) 
model_rank
model_rank=pull(model_rank,model)
resamp$values %>%
  dplyr::select(ends_with("Rsquared")) %>%
  pivot_longer('LM~Rsquared':'SVM~Rsquared',names_to = "model", values_to = "Rsquared",names_pattern = "(.*)~Rsquared") %>%
  mutate(model=factor(model,levels=model_rank)) %>%
  ggplot() +
  geom_density_ridges(aes(x=Rsquared,y=model,color=model,fill=model),alpha=0.5)
                         
```

```{r}
model <- c("linear_model","ridge","LASSO","elastic_net","PCR","GAM","MARS","ctree","bagging","boosting","SVM")
test_rmse <- c(lm.rmse, ridge.rmse, rmse_lasso, enet.rmse, pcr.rmse, rmse_gam, rmse_mars, rmse_tree, rmse_tree, rmse_gbm,test_error_svm)
test_rmse_df <- cbind(model, test_rmse)
test_rmse_df <- as.data.frame(test_rmse_df)
knitr::kable(test_rmse_df, "pipe")
```

```{r vip}
# Variable selection
vip(
  gbm_fit,
  method = "permute",
  train = train_dat,
  target = "recovery_t",
  metric = "RMSE",
  nsim = 10,
  pred_wrapper = predict,
  geom = "boxplot",
  all_permutations = TRUE,
  mapping = aes_string(fill = "Variable")
)
```

```{r}
ice2.rf <- gbm_fit %>% 
  partial(pred.var = "CRBI",
          grid.resolution = 100,
          ice = TRUE) %>% 
  autoplot(train = train_dat, 
           alpha = .1,
           center = TRUE) + 
  ggtitle("ICE, Boosting")
```